<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.1">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2021-12-10T17:01:55+09:00</updated><id>/feed.xml</id><title type="html">UrbanIntel</title><subtitle>Urban Intelligence for Smart City</subtitle><entry><title type="html">KDD-22 (Feb 10th, 2022)</title><link href="/conference/2021/12/06/KDD-22.html" rel="alternate" type="text/html" title="KDD-22 (Feb 10th, 2022)" /><published>2021-12-06T10:22:00+09:00</published><updated>2021-12-06T10:22:00+09:00</updated><id>/conference/2021/12/06/KDD-22</id><content type="html" xml:base="/conference/2021/12/06/KDD-22.html">&lt;h1 id=&quot;important-dates-time-anywhere-on-earth&quot;&gt;Important Dates (Time: Anywhere on Earth)&lt;/h1&gt;

&lt;p&gt;KDD is a dual track conference hosting both a Research and an Applied Data Science track. A paper should either be submitted to the Research or the Applied Science track but not both. Research track submissions are limited to nine (9 pages), including references, must be in PDF and use ACM Conference Proceeding templates. An additional two pages of supplemental material focused on reproducibility can be provided. Additionally, proofs and pseudo-code that could not be included in the main nine-page manuscript may also be included in the two-page supplement. Template guidelines are here: https://www.acm.org/publications/proceedings-template.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Paper Submission: Feb 10th, 2022&lt;/li&gt;
  &lt;li&gt;Final Notification: May 19th, 2022&lt;/li&gt;
  &lt;li&gt;Camera-ready: June 9th, 2022&lt;/li&gt;
  &lt;li&gt;Conference: August 14-18, 2022&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.kdd.org/kdd2022/cfpResearch.html&quot;&gt;https://www.kdd.org/kdd2022/cfpResearch.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;description&quot;&gt;Description&lt;/h1&gt;

&lt;p&gt;KDD is the premier Data Science conference. We invite original technical research contributions in all aspects of the data science lifecycle including but not limited to: data cleaning and preparation, data transformation, mining, inference, learning, explainability, data privacy, and dissemination of results. Technical data science contributions that advance United Nations Sustainable Development Goals (SDGs) are also encouraged. This year we are also inviting paper submissions that are at the intersection of data science and society as part of the research track.&lt;/p&gt;

&lt;p&gt;Data Cleaning and Preparation: A significant part of the data science lifecycle is spent on data cleaning and preparation. In several domains, data cleaning tasks continue to be rule-based and are often brittle, i.e., they break down in face of a constantly changing and evolving environment. Learning-based approaches for data cleaning and preparation which are generalizable and adaptive across domains are highly sought.&lt;/p&gt;

&lt;p&gt;Data Transformation and Integration: The process of mapping data from one representation into another is at the heart of data science. The mapping can be query driven, based on a statistical task, or might involve integrating data from myriad sources. We seek original contributions that address the trade-off between the complexity of the transformation and algorithmic efficiency.&lt;/p&gt;

&lt;p&gt;Mining, Inference, and Learning: These topics are the kernel of knowledge discovery from databases (KDD) paradigm and continue to witness massive growth. While classical aspects of supervised learning have been mainstreamed into the development cycle, new variations on unsupervised learning like self-supervision, few shot learning, prescriptive learning (reinforcement learning), transfer learning, meta learning, and representational learning are pushing the research boundary in a world where the proportion of labeled and annotated data is becoming minuscule. In each of these topics, we seek submissions that highlight the trade-off between accuracy, stability, robustness, and efficiency. Submissions that propose “new” inference tasks are strongly encouraged.&lt;/p&gt;

&lt;p&gt;Explainability: As data science models are becoming part of daily human activity there is a need, often being expressed in law, that the models be fair, interpretable, and provide mechanisms to explain how a prediction or decision by the model was arrived at. Interpretable models will lead to their wider acceptance in society at large and increase the value of Data Science as a discipline in its own right.&lt;/p&gt;

&lt;p&gt;Data Privacy and Ethics: Data privacy or lack thereof, continues to be the achilles heel of the whole data science enterprise. We seek technical contributions that advance the state of data science methods while guaranteeing individual privacy, respect for societal norms and ethical integrity.&lt;/p&gt;

&lt;p&gt;Model Dissemination: Migrating a data science model from a research lab to a real-world deployment is non-trivial and potentially a continuous ongoing process. We seek research submissions that highlight and address technical and behavioral challenges during model deployment, feedback, and upgradation.&lt;/p&gt;

&lt;p&gt;Data Science and Society: Data science has a critical role to play in addressing grand societal challenges, whether in addressing health inequities, climate change, resilience, sustainability, early childhood development, poverty, or other related areas. Success of data science in such areas is not just a function of data science alone, but it also requires careful engagement with the stakeholder, working across disciplines, and translation of the data science innovation towards achieving a societal impact. We invite papers that are at this interface, papers that demonstrate interdisciplinarity, papers that demonstrate stakeholder engagement, and papers that demonstrate a plan for realization of the data science application through translation. The innovation of these works may not be in the novelty of a data science method; rather, the innovation of these works will be at the careful exposition of societal challenge, and the role that data science and interdisciplinarity played towards addressing the societal challenge. The papers will be evaluated with this context. It is expected that papers have authors from different disciplines, and carefully situate the problem statement that is being solved, the role of data science, and societal impact evaluation.&lt;/p&gt;

&lt;h1 id=&quot;submission-guidelines&quot;&gt;Submission Guidelines&lt;/h1&gt;

&lt;p&gt;Papers submitted to KDD follow a double-blind review process. Every effort must be made to preserve the anonymity of the authors. Papers that have been presented as technical reports or workshop papers with listed authors will not be considered for review. An exception to the rule is the papers that have been submitted to arXiv at least one month prior to the deadline (January 8th, 2022), assuming these papers have not been submitted to any other venue (conference, workshop, journal., etc) for consideration or publication. Authors can submit these papers but with a different title and abstract. Papers that appear in arXiv after Jan 8th, 2022 until the end of the review process will not be accepted. After the submission deadline, authors are not allowed to add additional authors to the submitted papers.&lt;/p&gt;

&lt;p&gt;Conference Submission Website: https://cmt3.research.microsoft.com/SIGKDD2022&lt;/p&gt;

&lt;h1 id=&quot;important-policies&quot;&gt;Important policies&lt;/h1&gt;

&lt;h2 id=&quot;reproducibility&quot;&gt;Reproducibility&lt;/h2&gt;
&lt;p&gt;Submitted papers will be assessed based on their novelty, technical quality, potential impact, insightfulness, depth, clarity, and reproducibility. Authors are strongly encouraged to make their code and data publicly available, albeit anonymously during the review process. Algorithms and resources used in a paper should be described as completely as possible to allow reproducibility. This includes model parameters, experimental methodology, empirical evaluations, and results. The reproducibility factor will play an important role in the assessment of each submission.&lt;/p&gt;

&lt;h2 id=&quot;authorship&quot;&gt;Authorship&lt;/h2&gt;
&lt;p&gt;Every person named as the author of a paper must have contributed substantially both to the work described in the paper and to the writing of the paper. Every listed author must take responsibility for the entire content of a paper. Persons who do not meet these requirements may be acknowledged, but should not be listed as authors. Post-submission changes to the set of authors list are not allowed.&lt;/p&gt;

&lt;h2 id=&quot;dual-submissions&quot;&gt;Dual submissions&lt;/h2&gt;
&lt;p&gt;Submitted papers must describe work that is substantively different from work that has already been published, or accepted for publication. Papers submitted to SIGKDD cannot be simultaneously under review or consideration in any other venue (or in different tracks of KDD) during the entire SIGKDD review period (i.e., from paper submission to notification dates). This includes conferences, workshops, journals, and any other venues that have published proceedings.&lt;/p&gt;</content><author><name></name></author><category term="[&quot;Conference&quot;]" /><summary type="html">Important Dates (Time: Anywhere on Earth)</summary></entry><entry><title type="html">ICWSM-22 (Jan 15th, 2022)</title><link href="/conference/2021/12/06/ICWSM-22.html" rel="alternate" type="text/html" title="ICWSM-22 (Jan 15th, 2022)" /><published>2021-12-06T10:22:00+09:00</published><updated>2021-12-06T10:22:00+09:00</updated><id>/conference/2021/12/06/ICWSM-22</id><content type="html" xml:base="/conference/2021/12/06/ICWSM-22.html">&lt;ul&gt;
  &lt;li&gt;Important Dates: 3rd Full-paper Deadline: January 15, 2022 (by 23:59 PM Anywhere on Earth) (New submissions, and R&amp;amp;Rs from Sep 2021 submissions) [Notifications: Mar 15, 2022]&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.icwsm.org/2022/index.html/index.html#guidelines&quot;&gt;Guideliness&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;detailed-guidelines-for-paper-submission&quot;&gt;Detailed Guidelines for Paper Submission&lt;/h1&gt;
&lt;h2 id=&quot;content-guidelines&quot;&gt;Content Guidelines&lt;/h2&gt;
&lt;p&gt;Format: Papers must be in high resolution PDF format, formatted for US Letter (8.5” x 11”) paper, using Type 1 or TrueType fonts. Full papers are recommended to be 8 pages and must be at most 11 pages long, including references and any appendix. Note that the page limit is increased to 11 for papers submitted to the January 2022 deadline. This year, the page limit for the submission is increased to 11 pages in order to give space for the new requirement of an Ethics Statement (see more below). We highly encourage the authors to keep the main content of the paper to 10 pages, and use extra space for ethics considerations only. Note that the camera-ready is still limited to 12 pages as in the past years. Revision papers and final camera-ready full papers can be up to 12 pages. Dataset papers must be no longer than 10 pages, Poster papers must be no longer than 4 pages, and Demo descriptions must be no longer than 2 pages, and all must be submitted by the deadlines given above, and formatted in AAAI two-column, camera-ready style (templates can be found at https://www.aaai.org/Publications/Templates/AuthorKit21.zip). No source files (Word or LaTeX) are required at the time of submission for review; only the PDF file is permitted. Finally, the copyright slug may be omitted in the initial submission phase and no copyright form is required until a paper is accepted for publication.&lt;/p&gt;

&lt;p&gt;Anonymity: ICWSM-2022 review is double-blind. Therefore, please anonymize your submission: do not put the author(s) names or affiliation(s) at the start of the paper, and do not include funding or other acknowledgments in papers submitted for review. References to authors’ own prior relevant work should be included, but should not specify that this is the authors’ own work. Citations to the author’s own work should be anonymized, if possible, or can be added later to the final camera-ready version for publication. It is up to the authors’ discretion how much to further modify the body of the paper to preserve anonymity. The requirement for anonymity does not extend outside of the review process, e.g. the authors can decide how widely to distribute their papers over the Internet before the program committee meeting. Even in cases where the author’s identity is known to a reviewer, the double-blind process will serve as a symbolic reminder of the importance of evaluating the submitted work on its own merits without regard to authors’ reputation. Note that 2-page demo submissions and the dataset paper submissions, and only these, are exempt from the anonymization requirement as they often contain system URLs or URLs to data sharing services.&lt;/p&gt;

&lt;p&gt;Language: All submissions must be in English.&lt;/p&gt;

&lt;p&gt;Revisions: Papers that were previously submitted to ICWSM and received a “Revise and Resubmit “ decision should be accompanied by a copy of the previous reviews and an author response statement. The response statement may be in any format, but many reviewers appreciate a response that begins with an overall summary and then includes a table, with each row containing a reviewer comment in the left cell, and author’s response in the right cell. The response cell may explain why no changes were made, or may describe changes and direct the reviewer to a particular page, section, or figure, where the revised content appears. At the discretion of the Senior PC member handling the paper, the revised version may be sent back to some or all of the original reviewers for comment and evaluation, and may also be sent to additional reviewers.&lt;/p&gt;

&lt;p&gt;Broader perspective, ethics and competing interests: In order to provide a balanced perspective, authors are required to include a statement about the potential broader impact of their work and ethical considerations. This statement needs to, at the bare minimum, be presented in a clearly marked paragraph/subsection/section in your paper. Authors should take care to discuss both positive and negative outcomes. Authors are also expected to describe steps taken to prevent or mitigate potential negative outcomes. For full papers that have collected new datasets and for dataset papers, discuss ethical considerations in the data collection process, and considerations around its release, and both potentially positive and negative outcomes of its use by others.&lt;/p&gt;

&lt;p&gt;Authors are required to provide an explicit disclosure of funding (financial activities supporting the submitted work) and competing interests (related financial activities outside the submitted work) that could result in conflicts of interest. This section should be added to the camera-ready version of accepted papers and not for submission. Furthermore, authors are required to read the AAAI code of conduct and ethics guidelines and (i.) confirm that they abide by these rules and (ii.) discuss any concerns particularly relevant to their paper. Given a community as diverse as ICWSM, the issues related to ethics are likely to vary significantly across submissions. As such, we rely on you, the authors, to determine and cover the aspects most relevant to your work in your submission. Several checklists used in the past [1,2,3] can provide further guidance to scholars looking for starting points.&lt;/p&gt;

&lt;p&gt;Resubmission: Authors will need to declare if a previous version of their submission was rejected at any peer-reviewed venue, and, if so, summarize the changes made in the current version and include the original review. Authors of rejected papers from ICWSM may revise and submit their revised papers after 6 months of the date of the last decision, but not before. For example, papers submitted in the Jan round can be resubmitted to the September round (6 months after the decision in March) but not the May round. This decision was made to avoid paper rejections due to lack of time for revisions and to discourage authors from submitting papers that are not ready.&lt;/p&gt;

&lt;p&gt;Optional publication for social sciences and sociophysics papers
Researchers who wish to submit full papers without publication in the conference proceedings, may designate their submission as ‘social sciences and sociophysics (not for publication)’. Submissions must adhere to the formatting and content guidelines above. They will be reviewed according to the same process and criteria as all other full paper submissions. While we will not accept previously published papers, papers submitted as social sciences and sociophysics (not for publication) may be under review concurrently at a journal. Papers accepted to this track will be full presentations, integrated with the conference, but will be published only as abstracts in the ICWSM conference proceedings.&lt;/p&gt;

&lt;p&gt;Submissions originally designated as not for publication cannot be converted at the end to publication in the ICWSM conference proceedings, because that would provide a mechanism enabling simultaneous consideration of the same paper for publication in two venues. Researchers who do wish to publish their papers in the ICWSM proceedings should submit to the regular track. All submitted papers, whether targeted for publication or not, will be judged according to the same acceptance criteria.&lt;/p&gt;

&lt;h2 id=&quot;duplicate-submissions&quot;&gt;Duplicate Submissions&lt;/h2&gt;
&lt;p&gt;ICWSM-2022 will not accept any paper that, at the time of submission, is under review for or has already been published or accepted for publication in a journal or conference. This restriction does not apply to submissions for non-archival workshops.&lt;/p&gt;

&lt;p&gt;While we will not accept previously published papers, papers submitted as social sciences and sociophysics (not for publication) may be under review concurrently at a journal.&lt;/p&gt;

&lt;p&gt;If duplicate submissions are identified during the review process then:&lt;/p&gt;

&lt;p&gt;All submissions from that author will be disqualified from the current ICWSM conference;
And authors will not be permitted to submit papers to the ICWSM conference in the following year.&lt;/p&gt;

&lt;h2 id=&quot;conference-registration&quot;&gt;Conference Registration&lt;/h2&gt;
&lt;p&gt;Authors will be contacted about how to register for the conference. General registration for this year’s virtual conference will open soon. Stay tuned!&lt;/p&gt;

&lt;h2 id=&quot;publication&quot;&gt;Publication&lt;/h2&gt;
&lt;p&gt;All accepted papers and extended abstracts will be published in the conference proceedings, except for those submitted to the ‘social sciences and sociophysics (not for publication)’; only abstracts will be published for those. Though initial submissions of full papers must not exceed 11 pages, full papers accepted for publication will be allocated up to twelve (12) pages in the conference proceedings to facilitate to address comments raised by the reviewers. Authors will be required to transfer copyright to AAAI.&lt;/p&gt;

&lt;h2 id=&quot;datasets&quot;&gt;Datasets&lt;/h2&gt;
&lt;p&gt;ICWSM provides a service for hosting datasets pertaining to research presented at the conference. Authors of accepted papers will be encouraged to share the datasets on which their papers are based, while adhering to the terms and conditions of the data provider. Of these datasets, one will be selected for an award which will be based on the quality, scope, and timeliness of each dataset. More information will be available on our website.&lt;/p&gt;</content><author><name></name></author><category term="[&quot;Conference&quot;]" /><summary type="html">Important Dates: 3rd Full-paper Deadline: January 15, 2022 (by 23:59 PM Anywhere on Earth) (New submissions, and R&amp;amp;Rs from Sep 2021 submissions) [Notifications: Mar 15, 2022] Guideliness</summary></entry><entry><title type="html">Recent Deep Learning for Regional Traffic Prediction</title><link href="/ai/2021/12/06/RegionTrafficDeepNet.html" rel="alternate" type="text/html" title="Recent Deep Learning for Regional Traffic Prediction" /><published>2021-12-06T10:22:00+09:00</published><updated>2021-12-06T10:22:00+09:00</updated><id>/ai/2021/12/06/RegionTrafficDeepNet</id><content type="html" xml:base="/ai/2021/12/06/RegionTrafficDeepNet.html">&lt;p&gt;Regional traffic prediction&lt;/p&gt;

&lt;h1 id=&quot;overview&quot;&gt;Overview&lt;/h1&gt;

&lt;p&gt;More references are found here in this survey:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Deep learning for road traffic forecasting: Does it make a difference? &lt;a class=&quot;citation&quot; href=&quot;#manibardo2021deep&quot;&gt;[1]&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Graph neural network for traffic forecasting: A survey &lt;a class=&quot;citation&quot; href=&quot;#jiang2021graph&quot;&gt;[2]&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Traffic Prediction Survey &lt;a href=&quot;https://github.com/aprbw/traffic_prediction&quot;&gt;https://github.com/aprbw/traffic_prediction&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Papers with code &lt;a href=&quot;https://paperswithcode.com/task/traffic-prediction&quot;&gt;https://paperswithcode.com/task/traffic-prediction&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Conferences of interest:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;KDD&lt;/li&gt;
  &lt;li&gt;AAAI&lt;/li&gt;
  &lt;li&gt;CIKM&lt;/li&gt;
  &lt;li&gt;ICLR&lt;/li&gt;
  &lt;li&gt;WWW&lt;/li&gt;
  &lt;li&gt;SIGSPATIAL&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;regional-traffic-deepnet-models&quot;&gt;Regional Traffic DeepNet Models&lt;/h1&gt;

&lt;h2 id=&quot;convlstm-nips-15-3&quot;&gt;ConvLSTM (NIPS-15) &lt;a class=&quot;citation&quot; href=&quot;#DBLP:conf/nips/ShiCWYWW15&quot;&gt;[3]&lt;/a&gt;:&lt;/h2&gt;
&lt;p&gt;It extends LSTM to have convolutional structures to better capture spatio-temporal correlations.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Paper: &lt;a href=&quot;https://proceedings.neurips.cc/paper/2015/hash/07563a3fe3bbe7e3ba84431ad9d055af-Abstract.html&quot;&gt;Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;deepst-sigspatial-16-4&quot;&gt;DeepST (SIGSPATIAL-16) &lt;a class=&quot;citation&quot; href=&quot;#DBLP:conf/gis/ZhangZQLY16&quot;&gt;[4]&lt;/a&gt;:&lt;/h2&gt;
&lt;p&gt;The first deep learning-based prediction model for grid-based spatio-Temporal data.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Paper: &lt;a href=&quot;&quot;&gt;Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;st-resnet-aaai-17-5&quot;&gt;ST-ResNet (AAAI-17) &lt;a class=&quot;citation&quot; href=&quot;#DBLP:conf/aaai/ZhangZQ17&quot;&gt;[5]&lt;/a&gt;:&lt;/h2&gt;
&lt;p&gt;A ResNet-based method, which shows promising results on citywide crowd flows prediction.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Paper: &lt;a href=&quot;http://aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14501&quot;&gt;Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;st-3dnet-tits-19-6&quot;&gt;ST-3DNet (TITS-19) &lt;a class=&quot;citation&quot; href=&quot;#DBLP:journals/tits/GuoLLCW19&quot;&gt;[6]&lt;/a&gt;:&lt;/h2&gt;
&lt;p&gt;It uses 3D convolution to capture the correlation of traffic data in both spatial and temporal dimensions.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Paper: &lt;a href=&quot;&quot;&gt;Deep Spatial-Temporal 3D Convolutional Neural Networks for Traffic Data Forecasting&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;stdn-aaai-19-7&quot;&gt;STDN (AAAI-19) &lt;a class=&quot;citation&quot; href=&quot;#DBLP:conf/aaai/YaoTWZL19&quot;&gt;[7]&lt;/a&gt;:&lt;/h2&gt;
&lt;p&gt;It employs CNNs and LSTMs to capture spatial and temporal correlations separately, and an attention mechanism to model long-term periodic temporal shifting.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Paper: &lt;a href=&quot;https://doi.org/10.1609/aaai.v33i01.33015668&quot;&gt;Revisiting Spatial-Temporal Similarity: A Deep Learning Framework for Traffic Prediction.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;deepstn-aaai-19-8&quot;&gt;DeepSTN+ (AAAI-19) &lt;a class=&quot;citation&quot; href=&quot;#DBLP:conf/aaai/LinFLLJ19&quot;&gt;[8]&lt;/a&gt;:&lt;/h2&gt;
&lt;p&gt;The state-of-the-art method for urban flow prediction, which can capture long-term spatial dependencies as well as the effect of land functions.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Paper: &lt;a href=&quot;https://doi.org/10.1609/aaai.v33i01.33011020&quot;&gt;DeepSTN+: Context-Aware Spatial-Temporal Neural Network for Crowd Flow Prediction in Metropolis.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;strn-www-21-9&quot;&gt;STRN (WWW-21) &lt;a class=&quot;citation&quot; href=&quot;#DBLP:conf/www/LiangOSWZZRZ21&quot;&gt;[9]&lt;/a&gt;&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Paper: &lt;a href=&quot;https://doi.org/10.1145/3442381.3449792&quot;&gt;Fine-Grained Urban Flow Prediction&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Code: &amp;lt;&amp;gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;references&quot;&gt;References&lt;/h1&gt;
&lt;ol class=&quot;bibliography&quot;&gt;&lt;li&gt;&lt;span id=&quot;manibardo2021deep&quot;&gt;[1]Manibardo, E.L. et al. 2021. Deep learning for road traffic forecasting: Does it make a difference? &lt;i&gt;IEEE Transactions on Intelligent Transportation Systems&lt;/i&gt;. (2021).&lt;/span&gt;

&lt;a href=&quot;https://ieeexplore.ieee.org/abstract/document/9447807&quot; target=&quot;_blank&quot;&gt;link&lt;/a&gt;


&lt;!-- &lt;pre&gt;@article{manibardo2021deep,
  title = {Deep learning for road traffic forecasting: Does it make a difference?},
  author = {Manibardo, Eric L and La{\~n}a, Ibai and Del Ser, Javier},
  journal = {IEEE Transactions on Intelligent Transportation Systems},
  year = {2021},
  publisher = {IEEE},
  url = {https://ieeexplore.ieee.org/abstract/document/9447807}
}
&lt;/pre&gt; --&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;jiang2021graph&quot;&gt;[2]Jiang, W. and Luo, J. 2021. Graph neural network for traffic forecasting: A survey. &lt;i&gt;arXiv preprint arXiv:2101.11174&lt;/i&gt;. (2021).&lt;/span&gt;

&lt;a href=&quot;https://arxiv.org/abs/2101.11174&quot; target=&quot;_blank&quot;&gt;link&lt;/a&gt;


&lt;!-- &lt;pre&gt;@article{jiang2021graph,
  title = {Graph neural network for traffic forecasting: A survey},
  author = {Jiang, Weiwei and Luo, Jiayun},
  journal = {arXiv preprint arXiv:2101.11174},
  year = {2021},
  url = {https://arxiv.org/abs/2101.11174}
}
&lt;/pre&gt; --&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;DBLP:conf/nips/ShiCWYWW15&quot;&gt;[3]Shi, X. et al. 2015. Convolutional LSTM Network: A Machine Learning Approach for Precipitation
               Nowcasting. &lt;i&gt;Advances in Neural Information Processing Systems 28: Annual Conference
               on Neural Information Processing Systems 2015, December 7-12, 2015,
               Montreal, Quebec, Canada&lt;/i&gt; (2015), 802–810.&lt;/span&gt;

&lt;a href=&quot;https://proceedings.neurips.cc/paper/2015/hash/07563a3fe3bbe7e3ba84431ad9d055af-Abstract.html&quot; target=&quot;_blank&quot;&gt;link&lt;/a&gt;


&lt;!-- &lt;pre&gt;@inproceedings{DBLP:conf/nips/ShiCWYWW15,
  author = {Shi, Xingjian and Chen, Zhourong and Wang, Hao and Yeung, Dit{-}Yan and Wong, Wai{-}Kin and Woo, Wang{-}chun},
  editor = {Cortes, Corinna and Lawrence, Neil D. and Lee, Daniel D. and Sugiyama, Masashi and Garnett, Roman},
  title = {Convolutional {LSTM} Network: {A} Machine Learning Approach for Precipitation
                 Nowcasting},
  booktitle = {Advances in Neural Information Processing Systems 28: Annual Conference
                 on Neural Information Processing Systems 2015, December 7-12, 2015,
                 Montreal, Quebec, Canada},
  pages = {802--810},
  year = {2015},
  url = {https://proceedings.neurips.cc/paper/2015/hash/07563a3fe3bbe7e3ba84431ad9d055af-Abstract.html},
  timestamp = {Thu, 21 Jan 2021 15:15:22 +0100},
  biburl = {https://dblp.org/rec/conf/nips/ShiCWYWW15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
&lt;/pre&gt; --&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;DBLP:conf/gis/ZhangZQLY16&quot;&gt;[4]Zhang, J. et al. 2016. DNN-based prediction model for spatio-temporal data. &lt;i&gt;Proceedings of the 24th ACM SIGSPATIAL International Conference
               on Advances in Geographic Information Systems, GIS 2016, Burlingame,
               California, USA, October 31 - November 3, 2016&lt;/i&gt; (2016), 92:1–92:4.&lt;/span&gt;

&lt;a href=&quot;https://doi.org/10.1145/2996913.2997016&quot; target=&quot;_blank&quot;&gt;link&lt;/a&gt;


&lt;!-- &lt;pre&gt;@inproceedings{DBLP:conf/gis/ZhangZQLY16,
  author = {Zhang, Junbo and Zheng, Yu and Qi, Dekang and Li, Ruiyuan and Yi, Xiuwen},
  editor = {Ravada, Siva and Ali, Mohammed Eunus and Newsam, Shawn D. and Renz, Matthias and Trajcevski, Goce},
  title = {DNN-based prediction model for spatio-temporal data},
  booktitle = {Proceedings of the 24th {ACM} {SIGSPATIAL} International Conference
                 on Advances in Geographic Information Systems, {GIS} 2016, Burlingame,
                 California, USA, October 31 - November 3, 2016},
  pages = {92:1--92:4},
  publisher = {{ACM}},
  year = {2016},
  url = {https://doi.org/10.1145/2996913.2997016},
  doi = {10.1145/2996913.2997016},
  timestamp = {Tue, 06 Nov 2018 11:07:36 +0100},
  biburl = {https://dblp.org/rec/conf/gis/ZhangZQLY16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
&lt;/pre&gt; --&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;DBLP:conf/aaai/ZhangZQ17&quot;&gt;[5]Zhang, J. et al. 2017. Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction. &lt;i&gt;Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence,
               February 4-9, 2017, San Francisco, California, USA&lt;/i&gt; (2017), 1655–1661.&lt;/span&gt;

&lt;a href=&quot;http://aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14501&quot; target=&quot;_blank&quot;&gt;link&lt;/a&gt;


&lt;!-- &lt;pre&gt;@inproceedings{DBLP:conf/aaai/ZhangZQ17,
  author = {Zhang, Junbo and Zheng, Yu and Qi, Dekang},
  editor = {Singh, Satinder P. and Markovitch, Shaul},
  title = {Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction},
  booktitle = {Proceedings of the Thirty-First {AAAI} Conference on Artificial Intelligence,
                 February 4-9, 2017, San Francisco, California, {USA}},
  pages = {1655--1661},
  publisher = {{AAAI} Press},
  year = {2017},
  url = {http://aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14501},
  timestamp = {Wed, 10 Feb 2021 08:44:46 +0100},
  biburl = {https://dblp.org/rec/conf/aaai/ZhangZQ17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
&lt;/pre&gt; --&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;DBLP:journals/tits/GuoLLCW19&quot;&gt;[6]Guo, S. et al. 2019. Deep Spatial-Temporal 3D Convolutional Neural Networks for Traffic
               Data Forecasting. &lt;i&gt;IEEE Trans. Intell. Transp. Syst.&lt;/i&gt; 20, 10 (2019), 3913–3926. DOI:https://doi.org/10.1109/TITS.2019.2906365.&lt;/span&gt;

&lt;a href=&quot;https://doi.org/10.1109/TITS.2019.2906365&quot; target=&quot;_blank&quot;&gt;link&lt;/a&gt;


&lt;!-- &lt;pre&gt;@article{DBLP:journals/tits/GuoLLCW19,
  author = {Guo, Shengnan and Lin, Youfang and Li, Shijie and Chen, Zhaoming and Wan, Huaiyu},
  title = {Deep Spatial-Temporal 3D Convolutional Neural Networks for Traffic
                 Data Forecasting},
  journal = {{IEEE} Trans. Intell. Transp. Syst.},
  volume = {20},
  number = {10},
  pages = {3913--3926},
  year = {2019},
  url = {https://doi.org/10.1109/TITS.2019.2906365},
  doi = {10.1109/TITS.2019.2906365},
  timestamp = {Tue, 08 Sep 2020 14:08:58 +0200},
  biburl = {https://dblp.org/rec/journals/tits/GuoLLCW19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
&lt;/pre&gt; --&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;DBLP:conf/aaai/YaoTWZL19&quot;&gt;[7]Yao, H. et al. 2019. Revisiting Spatial-Temporal Similarity: A Deep Learning Framework
               for Traffic Prediction. &lt;i&gt;The Thirty-Third AAAI Conference on Artificial Intelligence, AAAI
               2019, The Thirty-First Innovative Applications of Artificial Intelligence
               Conference, IAAI 2019, The Ninth AAAI Symposium on Educational
               Advances in Artificial Intelligence, EAAI 2019, Honolulu, Hawaii,
               USA, January 27 - February 1, 2019&lt;/i&gt; (2019), 5668–5675.&lt;/span&gt;

&lt;a href=&quot;https://doi.org/10.1609/aaai.v33i01.33015668&quot; target=&quot;_blank&quot;&gt;link&lt;/a&gt;


&lt;!-- &lt;pre&gt;@inproceedings{DBLP:conf/aaai/YaoTWZL19,
  author = {Yao, Huaxiu and Tang, Xianfeng and Wei, Hua and Zheng, Guanjie and Li, Zhenhui},
  title = {Revisiting Spatial-Temporal Similarity: {A} Deep Learning Framework
                 for Traffic Prediction},
  booktitle = {The Thirty-Third {AAAI} Conference on Artificial Intelligence, {AAAI}
                 2019, The Thirty-First Innovative Applications of Artificial Intelligence
                 Conference, {IAAI} 2019, The Ninth {AAAI} Symposium on Educational
                 Advances in Artificial Intelligence, {EAAI} 2019, Honolulu, Hawaii,
                 USA, January 27 - February 1, 2019},
  pages = {5668--5675},
  publisher = {{AAAI} Press},
  year = {2019},
  url = {https://doi.org/10.1609/aaai.v33i01.33015668},
  doi = {10.1609/aaai.v33i01.33015668},
  timestamp = {Tue, 02 Feb 2021 07:59:43 +0100},
  biburl = {https://dblp.org/rec/conf/aaai/YaoTWZL19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
&lt;/pre&gt; --&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;DBLP:conf/aaai/LinFLLJ19&quot;&gt;[8]Lin, Z. et al. 2019. DeepSTN+: Context-Aware Spatial-Temporal Neural Network for Crowd
               Flow Prediction in Metropolis. &lt;i&gt;The Thirty-Third AAAI Conference on Artificial Intelligence, AAAI
               2019, The Thirty-First Innovative Applications of Artificial Intelligence
               Conference, IAAI 2019, The Ninth AAAI Symposium on Educational
               Advances in Artificial Intelligence, EAAI 2019, Honolulu, Hawaii,
               USA, January 27 - February 1, 2019&lt;/i&gt; (2019), 1020–1027.&lt;/span&gt;

&lt;a href=&quot;https://doi.org/10.1609/aaai.v33i01.33011020&quot; target=&quot;_blank&quot;&gt;link&lt;/a&gt;


&lt;!-- &lt;pre&gt;@inproceedings{DBLP:conf/aaai/LinFLLJ19,
  author = {Lin, Ziqian and Feng, Jie and Lu, Ziyang and Li, Yong and Jin, Depeng},
  title = {DeepSTN+: Context-Aware Spatial-Temporal Neural Network for Crowd
                 Flow Prediction in Metropolis},
  booktitle = {The Thirty-Third {AAAI} Conference on Artificial Intelligence, {AAAI}
                 2019, The Thirty-First Innovative Applications of Artificial Intelligence
                 Conference, {IAAI} 2019, The Ninth {AAAI} Symposium on Educational
                 Advances in Artificial Intelligence, {EAAI} 2019, Honolulu, Hawaii,
                 USA, January 27 - February 1, 2019},
  pages = {1020--1027},
  publisher = {{AAAI} Press},
  year = {2019},
  url = {https://doi.org/10.1609/aaai.v33i01.33011020},
  doi = {10.1609/aaai.v33i01.33011020},
  timestamp = {Tue, 02 Feb 2021 08:00:41 +0100},
  biburl = {https://dblp.org/rec/conf/aaai/LinFLLJ19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
&lt;/pre&gt; --&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;DBLP:conf/www/LiangOSWZZRZ21&quot;&gt;[9]Liang, Y. et al. 2021. Fine-Grained Urban Flow Prediction. &lt;i&gt;WWW ’21: The Web Conference 2021, Virtual Event / Ljubljana, Slovenia,
               April 19-23, 2021&lt;/i&gt; (2021), 1833–1845.&lt;/span&gt;

&lt;a href=&quot;https://doi.org/10.1145/3442381.3449792&quot; target=&quot;_blank&quot;&gt;link&lt;/a&gt;


&lt;!-- &lt;pre&gt;@inproceedings{DBLP:conf/www/LiangOSWZZRZ21,
  author = {Liang, Yuxuan and Ouyang, Kun and Sun, Junkai and Wang, Yiwei and Zhang, Junbo and Zheng, Yu and Rosenblum, David S. and Zimmermann, Roger},
  editor = {Leskovec, Jure and Grobelnik, Marko and Najork, Marc and Tang, Jie and Zia, Leila},
  title = {Fine-Grained Urban Flow Prediction},
  booktitle = {{WWW} '21: The Web Conference 2021, Virtual Event / Ljubljana, Slovenia,
                 April 19-23, 2021},
  pages = {1833--1845},
  publisher = {{ACM} / {IW3C2}},
  year = {2021},
  url = {https://doi.org/10.1145/3442381.3449792},
  doi = {10.1145/3442381.3449792},
  timestamp = {Mon, 05 Jul 2021 22:07:07 +0200},
  biburl = {https://dblp.org/rec/conf/www/LiangOSWZZRZ21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
&lt;/pre&gt; --&gt;&lt;/li&gt;&lt;/ol&gt;</content><author><name></name></author><category term="[&quot;AI&quot;]" /><summary type="html">Regional traffic prediction</summary></entry><entry><title type="html">IJCAI-22 (Jan 7th, 2022)</title><link href="/conference/2021/12/05/IJCAI-22.html" rel="alternate" type="text/html" title="IJCAI-22 (Jan 7th, 2022)" /><published>2021-12-05T10:22:00+09:00</published><updated>2021-12-05T10:22:00+09:00</updated><id>/conference/2021/12/05/IJCAI-22</id><content type="html" xml:base="/conference/2021/12/05/IJCAI-22.html">&lt;p&gt;Important Dates&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Submission site opening: December 30, 2021&lt;/li&gt;
  &lt;li&gt;Abstract submission deadline: January 7, 2022&lt;/li&gt;
  &lt;li&gt;Author information deadline: January 10, 2022&lt;/li&gt;
  &lt;li&gt;Full paper submission deadline: January 14, 2022&lt;/li&gt;
  &lt;li&gt;Summary reject notification: February 18, 2022&lt;/li&gt;
  &lt;li&gt;Author response period: March 16-18, 2022&lt;/li&gt;
  &lt;li&gt;Paper discussion phase: March 19-29, 2022&lt;/li&gt;
  &lt;li&gt;Paper notification: April 20, 2022&lt;/li&gt;
  &lt;li&gt;Camera ready: April 30, 2022&lt;/li&gt;
  &lt;li&gt;Submissions are invited for the 31st International Joint Conference on Artificial Intelligence and the 23rd European Conference on Artificial Intelligence (IJCAI-ECAI 2022), which is planned to be held in Vienna, Austria, from July  23rd to July 29th, 2022. Starting from 1969, IJCAI has remained the premier conference bringing together the international AI community to communicate the advances and achievements of artificial intelligence research.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Submissions to IJCAI-ECAI 22 should report on significant, original, and previously unpublished results on any aspect of artificial intelligence. Papers on novel AI research problems, on AI techniques for novel application domains, and papers that cross discipline boundaries within AI are especially encouraged.&lt;/p&gt;

&lt;h1 id=&quot;key-novelties-this-year&quot;&gt;Key novelties this year:&lt;/h1&gt;

&lt;p&gt;Two phase reviewing process. Only papers that receive two sufficiently positive reviews during the first phase will proceed to the second full reviewing phase. 
The program committee consists of PC members (reviewers), Senior PC members (meta-reviewers) and Area Chairs (ACs), who overview the reviewing and meta-reviewing process.
The author response (for papers in the second phase only) will be accessible to PCs, SPCs, and ACs. 
There are two special tracks (“AI for Good”, and “AI, the Arts and Creativity”) with separate calls for papers. 
The authors of papers submitted to IJCAI-ECAI 2022 are expected to contribute a limited number of reviews, if asked to. 
Please observe the requirements with regard to author information, anonymity, resubmissions, reproducibility checklist (updated), and submission limits.&lt;/p&gt;

&lt;h1 id=&quot;selection-process&quot;&gt;Selection Process&lt;/h1&gt;
&lt;p&gt;Selection criteria:  Selection criteria include the novelty and originality of ideas, correctness, clarity, significance of results, potential impact and quality of the presentation.&lt;/p&gt;

&lt;p&gt;Summary rejects: The reviewing process proceeds in two phases. In Phase 1, every paper will be reviewed by two reviewers and if a paper receives two reviews that are not sufficiently positive in Phase 1, it will be rejected without any opportunity to submit an author response.  By submitting a paper, authors acknowledge that they are aware of the possibility of receiving a summary rejection notification.&lt;/p&gt;

&lt;p&gt;Full paper review: Papers passing the summary reject step will go through the full reviewing process. Each paper will be reviewed by a group of  PC-members (PCs), and a Senior PC member (SPC) will coordinate the PC review process and write a meta-review with a recommendation, cross-checked by an Area Chair (AC).&lt;/p&gt;

&lt;p&gt;Author response: The full paper review process will include the opportunity for authors to respond to the reviews by pointing out factual errors in the reviews and answering specific questions by the reviewers. Author responses should be concise, and are not intended to create a dialogue between reviewers and authors. Author responses will be visible to AC, SPC, and PCs.&lt;/p&gt;

&lt;p&gt;Triple blind reviewing: From the perspective of the Senior Program Committee members (SPC) and Program Committee members (PC),  the reviewing process will be triple blind, i.e., SPC/PCs cannot see the identities of authors and other SPC/PCs, and vice versa. Author identities are also invisible to Area Chairs (ACs) and vice versa.&lt;/p&gt;

&lt;p&gt;Participation in the conference.  At least one author of each accepted paper is required to participate in the conference and present the work. We are looking forward to the community meeting in person. At the same time, we are also closely observing the global public health situation.&lt;/p&gt;

&lt;p&gt;Ethics and conflict of interest policy: All individuals involved in the IJCAI-ECAI 2022 review process must adhere to the IJCAI conflict of interest policy. Details can be found at https://www.ijcai.org/IJCAI_Conflict_of_Interest_Policy.pdf. All authors of papers submitted to IJCAI-ECAI 2022 agree to be bound by the conditions outlined in this call for papers (w.r.t. multiple submissions, authorship, resubmission policy, submission limit, etc.). Authors and reviewers acknowledge that IJCAI may take action upon individuals in breach with the conflict of interest and call for papers policy including – but not limited to – rejecting their submissions without further review and banning individuals from submitting their work to a limited number of IJCAI conferences in the future.&lt;/p&gt;

&lt;p&gt;Withdrawing submitted papers: all papers that are withdrawn from the conference after February 1, 2022, will also be formally rejected from IJCAI-ECAI 2022.&lt;/p&gt;

&lt;p&gt;Confidentiality policy: All submissions will be treated in strict confidence until the publication date.&lt;/p&gt;

&lt;h1 id=&quot;submission-process&quot;&gt;Submission Process&lt;/h1&gt;
&lt;p&gt;Formatting guidelines: LaTeX styles, and Word template: https://www.ijcai.org/authors_kit&lt;/p&gt;

&lt;p&gt;Submission site: https://cmt3.research.microsoft.com/IJCAI2022&lt;/p&gt;

&lt;p&gt;Mandatory abstract submission: The paper title, author names, contact details, and a brief abstract must be submitted electronically through the IJCAI-ECAI 22 paper submission site (link above) by the abstract submission deadline. It will be possible to make minor edits to the title and abstract until the full paper submission deadline. Submissions with “placeholder” abstracts will be removed without consideration.&lt;/p&gt;

&lt;p&gt;Author Information: Full papers must be submitted through the same site by the paper submission deadline. The list of author names provided at Author Information Deadline is final. Authors may not be added to, or removed from, papers following submission. (The author ordering may still be changed during the camera-ready period.)&lt;/p&gt;

&lt;p&gt;All authors are required to log in and fill out a user information form in CMT by the Author Information deadline. The author information is important to control the COIs in the review process. If any co-author does not register and enters the necessary information, a submission may be rejected without review.&lt;/p&gt;

&lt;p&gt;Finally, for each submitted paper to IJCAI-ECAI 2022 the set of authors commits themselves to review up to three submissions, if asked to. This does not apply to papers submitted by members of the program committee and when extenuating circumstances apply.&lt;/p&gt;

&lt;p&gt;Submission limit: IJCAI-ECAI 22 is enforcing a strict submission limit. Each individual author is limited to no more than 8 submissions to the main track of IJCAI-ECAI 22.&lt;/p&gt;

&lt;p&gt;Keywords: When submitting abstracts, authors will be required to choose up to three content area keywords. General categories should be used only if specific categories do not apply or do not accurately reflect the main contributions. The full list of keywords will be available on the submission site.&lt;/p&gt;

&lt;p&gt;Copyright:  IJCAI-ECAI 22 is a conference held under the IJCAI rules. The papers published there will be solely IJCAI publications with IJCAI as copyright holder.&lt;/p&gt;

&lt;h1 id=&quot;submission-requirements&quot;&gt;Submission Requirements&lt;/h1&gt;
&lt;p&gt;Paper format: Papers submitted to  IJCAI-ECAI 22 must be formatted according to the IJCAI-ECAI 22 guidelines (link above). Submissions must be self-contained. Authors are required to submit their electronic papers in PDF format. Submissions that violate the  IJCAI-ECAI 22 style (e.g., by decreasing margins or font sizes) may be rejected without review.&lt;/p&gt;

&lt;p&gt;Paper length: Papers must be no longer than 7 pages in total: 6 pages for the body of the paper (including all figures/tables), plus up to 1 additional page with references that do not fit within the six body pages. (For accepted papers, up to two additional pages may be purchased at an additional cost per page; note that, at the time of submission, papers are required to adhere to the 6+1 format above.) Overlength papers will be rejected without review.&lt;/p&gt;

&lt;p&gt;Supplementary file: Authors may submit up to 50MB of supplementary material, such as appendices, proofs, derivations, data, or source code; all supplementary material must be in PDF or ZIP format. Supplementary material should be material, created by the authors, that directly supports the submission content. Like submissions, supplementary material must be anonymized. To submit supplementary material, first upload your submission. You will then be able to upload supplementary material from the author console. There are two entries for supplementary files: one is “TechnicalAppendix”, and the other one is “ResubmissionFile”. The latter one can be ignored if you are not resubmitting paper rejected at any peer-reviewed conference within the past 6 months. Looking at supplementary material is at the discretion of the reviewers.&lt;/p&gt;

&lt;p&gt;Anonymity: From the perspective of the authors, reviewing for  IJCAI-ECAI 22 is double blind. As an author, you are responsible for anonymizing your submission. In particular, you should not include author names or affiliations in your submission, and you should avoid providing any other identifying information (even in the supplementary material). Acknowledgments of funding or assistance should also be omitted. When referring to one’s own work, use the third person, rather than the first person. For example, say “Previously, Dechter and De Raedt [8] have shown that…”, rather than “In our previous work [8], we have shown that…”. All identifying information can be added back to the final camera-ready version of accepted papers. Supplementary materials and code should also be anonymized (including, for instance, hardcoded paths or URLs that may give away login identifiers or institutions). Submissions that violate anonymity will be rejected without further review.&lt;/p&gt;

&lt;p&gt;Preprints: The existence of non-anonymous preprints (on arXiv, social media, websites, etc.) will not result in rejection. Note that the submission to CMT must always be anonymized regardless of whether a preprint has been released. Reviewers will be instructed not to actively look for such preprints, but encountering them will not constitute a conflict of interest.&lt;/p&gt;

&lt;p&gt;Reproducibility: Authors must follow the reproducibility guidelines (not yet available) and checklist at the time of paper submission. In case of questions related to reproducibility, please contact the Reproducibility Co-chairs (Johannes Fürnkranz and Pierre Marquis via reproducibility@ijcai-22.org)&lt;/p&gt;

&lt;p&gt;Ethical/societal impact: It is optional for authors to include a statement of the potential broader impact of their work, including its ethical aspects and future societal consequences. This part can be put in either the main body of the paper or the reference page.&lt;/p&gt;

&lt;p&gt;Resubmissions: Authors of papers that have been rejected at any peer-reviewed conference within the past 6 months must declare the resubmission by including a cover letter with their submission. The cover letter should summarize the main reasons for rejection and should describe the changes the authors have made to address the reviewers’ comments. The cover letter should be put in a separate file, along with the previous reviews and previous anonymized rejected submission. Such resubmissions must contain, in a single PDF file (different from the IJCAI-ECAI 22 paper file):&lt;/p&gt;

&lt;p&gt;the cover letter, starting with the title of the rejected paper, the tracking number (if any), and the name of the conference to which this paper was submitted,
the full reviews from the rejected conference,
the anonymized version of the rejected paper.
This resubmission information will be visible to reviewers only during the discussion phase after they submit their initial review.&lt;/p&gt;

&lt;p&gt;To submit a resubmission file PDF, first upload your submission. You will then be able to upload a resubmission file from the author console as a supplementary file. There are two entries for supplementary files: one is “TechnicalAppendix”, which is the normal supplementary file for the main paper; and the other one is “ResubmissionFile”, to which you should upload the resubmission file. Note that the maximal size of the resubmission PDF is 10M.&lt;/p&gt;

&lt;p&gt;Dual submissions: IJCAI-ECAI 22 will not accept any paper that, at the time of submission, is under review for, has already been published in, or has already been accepted for publication in a journal or another venue with formally published proceedings. (As a guideline, authors should regard publications with a DOI, ISBN, or ISSN as formal publications. Questions about submission eligibility should be referred to the program chair before the submission deadline.) Authors are also required not to submit their papers to venues with formally published proceedings during the  IJCAI-ECAI 22 review period. These restrictions do not apply to workshops and similar specialized presentations with a limited audience and without published proceedings.&lt;/p&gt;</content><author><name></name></author><category term="[&quot;Conference&quot;]" /><summary type="html">Important Dates</summary></entry><entry><title type="html">Recent Deep Learning for Road Traffic Prediction</title><link href="/ai/2021/12/03/RoadTrafficDeepNet.html" rel="alternate" type="text/html" title="Recent Deep Learning for Road Traffic Prediction" /><published>2021-12-03T10:22:00+09:00</published><updated>2021-12-03T10:22:00+09:00</updated><id>/ai/2021/12/03/RoadTrafficDeepNet</id><content type="html" xml:base="/ai/2021/12/03/RoadTrafficDeepNet.html">&lt;h1 id=&quot;overview&quot;&gt;Overview&lt;/h1&gt;

&lt;p&gt;Urban Computing Mind Map:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/posts/Urban-computing-english.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;More references are found here in this survey:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Deep learning for road traffic forecasting: Does it make a difference? &lt;a class=&quot;citation&quot; href=&quot;#manibardo2021deep&quot;&gt;[1]&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Graph neural network for traffic forecasting: A survey &lt;a class=&quot;citation&quot; href=&quot;#jiang2021graph&quot;&gt;[2]&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Traffic Prediction Survey &lt;a href=&quot;https://github.com/aprbw/traffic_prediction&quot;&gt;https://github.com/aprbw/traffic_prediction&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;GNN4Traffic &lt;a href=&quot;https://github.com/jwwthu/GNN4Traffic&quot;&gt;https://github.com/jwwthu/GNN4Traffic&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Survey: &lt;a href=&quot;https://ieeexplore.ieee.org/abstract/document/9204396&quot;&gt;https://ieeexplore.ieee.org/abstract/document/9204396&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Papers with code &lt;a href=&quot;https://paperswithcode.com/task/traffic-prediction&quot;&gt;https://paperswithcode.com/task/traffic-prediction&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Conferences of interest:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;KDD&lt;/li&gt;
  &lt;li&gt;AAAI&lt;/li&gt;
  &lt;li&gt;CIKM&lt;/li&gt;
  &lt;li&gt;ICLR&lt;/li&gt;
  &lt;li&gt;WWW&lt;/li&gt;
  &lt;li&gt;SIGSPATIAL&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;traffic-prediction-on-metr-la&quot;&gt;&lt;a href=&quot;https://paperswithcode.com/sota/traffic-prediction-on-metr-la&quot;&gt;Traffic Prediction on METR-LA&lt;/a&gt;&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Rank&lt;/th&gt;
      &lt;th&gt;Model&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;MAE @ 12 step&lt;/th&gt;
      &lt;th&gt;Paper&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Code&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Result&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Year&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Tags&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td&gt;Traffic Transformer&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;3.28&lt;/td&gt;
      &lt;td&gt;Traffic transformer: Capturing the continuity and periodicity of time series for traffic forecasting&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;2020&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;2&lt;/td&gt;
      &lt;td&gt;SLCNN&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;3.3&lt;/td&gt;
      &lt;td&gt;Spatio-Temporal Graph Structure Learning for Traffic Forecasting&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;2020&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;3&lt;/td&gt;
      &lt;td&gt;STAWnet&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;3.44&lt;/td&gt;
      &lt;td&gt;Spatial‐temporal attention wavenet: A deep learning framework for traffic prediction considering spatial‐temporal dependencies&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;v&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;2021&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;4&lt;/td&gt;
      &lt;td&gt;Finetune from t1-6 checkpoint&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;3.47&lt;/td&gt;
      &lt;td&gt;Incrementally Improving Graph WaveNet Performance on Traffic Prediction&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;v&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;2019&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;5&lt;/td&gt;
      &lt;td&gt;MRA-BGCN&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;3.49&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;2020&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;GCN&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;6&lt;/td&gt;
      &lt;td&gt;GWNET-Cov&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;3.50&lt;/td&gt;
      &lt;td&gt;Conditional Temporal Neural Processes with Covariance Loss&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;v&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;2021&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;7&lt;/td&gt;
      &lt;td&gt;Graph WaveNet&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;3.53&lt;/td&gt;
      &lt;td&gt;Graph WaveNet for Deep Spatial-Temporal Graph Modeling&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;v&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;2019&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;8&lt;/td&gt;
      &lt;td&gt;ST-UNet&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;3.55&lt;/td&gt;
      &lt;td&gt;ST-UNet: A Spatio-Temporal U-Network for Graph-structured Time Series Modeling&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;2019&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;9&lt;/td&gt;
      &lt;td&gt;DCRNN&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;3.60&lt;/td&gt;
      &lt;td&gt;Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;v&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;2017&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;10&lt;/td&gt;
      &lt;td&gt;STGCN&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;4.45&lt;/td&gt;
      &lt;td&gt;Spatio-Temporal Graph Convolutional Networks: A Deep Learning Framework for Traffic Forecasting&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;v&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;2017&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;GCN&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;traffic-prediction-on-pems-bay&quot;&gt;&lt;a href=&quot;https://paperswithcode.com/sota/traffic-prediction-on-pems-bay&quot;&gt;Traffic Prediction on PEMS-BAY&lt;/a&gt;&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Rank&lt;/th&gt;
      &lt;th&gt;Model&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;MAE @ 12 step&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;RMSE&lt;/th&gt;
      &lt;th&gt;Paper&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Code&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Result&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Year&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Tags&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td&gt;Traffic Transformer&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1.77&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td&gt;Traffic transformer: Capturing the continuity and periodicity of time series for traffic forecasting&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;2020&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;2&lt;/td&gt;
      &lt;td&gt;STGNN&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1.83&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;3&lt;/td&gt;
      &lt;td&gt;STNN&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1.86&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;4.22&lt;/td&gt;
      &lt;td&gt;Space Meets Time: Local Spacetime Neural Network For Traffic Flow Forecasting&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;v&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;2021&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;4&lt;/td&gt;
      &lt;td&gt;GMAN&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1.86&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;4.32&lt;/td&gt;
      &lt;td&gt;GMAN: A Graph Multi-Attention Network for Traffic Prediction&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;v&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;2019&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;5&lt;/td&gt;
      &lt;td&gt;STAWnet&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1.89&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td&gt;Spatial‐temporal attention wavenet: A deep learning framework for traffic prediction considering spatial‐temporal dependencies&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;v&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;2021&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;6&lt;/td&gt;
      &lt;td&gt;GWNET-Cov&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1.91&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;4.40&lt;/td&gt;
      &lt;td&gt;Conditional Temporal Neural Processes with Covariance Loss&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;v&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;2021&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;7&lt;/td&gt;
      &lt;td&gt;Graph Wave-Net&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1.95&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;4.52&lt;/td&gt;
      &lt;td&gt;Graph WaveNet for Deep Spatial-Temporal Graph Modeling&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;v&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;2019&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;8&lt;/td&gt;
      &lt;td&gt;SLCNN&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;2.03&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td&gt;Spatio-Temporal Graph Structure Learning for Traffic Forecasting&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;2020&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;9&lt;/td&gt;
      &lt;td&gt;DCRNN&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;2.07&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;4.74&lt;/td&gt;
      &lt;td&gt;Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;v&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;2017&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;10&lt;/td&gt;
      &lt;td&gt;STBayesian&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;4.44&lt;/td&gt;
      &lt;td&gt;Traffic signal prediction on transportation networks using spatio-temporal correlations on graphs&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;v&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;2021&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h1 id=&quot;traffic-deepnet-models&quot;&gt;Traffic DeepNet Models&lt;/h1&gt;

&lt;h2 id=&quot;dcrnn-iclr-18-3&quot;&gt;DCRNN (ICLR-18) &lt;a class=&quot;citation&quot; href=&quot;#DBLP:conf/iclr/LiYS018&quot;&gt;[3]&lt;/a&gt;&lt;/h2&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://github.com/liyaguang/DCRNN/raw/master/figures/model_architecture.jpg&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Paper: &lt;a href=&quot;https://openreview.net/forum?id=SJiHXGWAZ&quot;&gt;Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Code: &lt;a href=&quot;https://github.com/liyaguang/DCRNN&quot;&gt;https://github.com/liyaguang/DCRNN&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;st-gcn-ijcai-18-4&quot;&gt;ST-GCN (IJCAI-18) &lt;a class=&quot;citation&quot; href=&quot;#DBLP:conf/ijcai/YuYZ18&quot;&gt;[4]&lt;/a&gt;&lt;/h2&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://github.com/VeritasYin/STGCN_IJCAI-18/raw/master/figures/Graph_Structured_Traffic_Data.png&quot; width=&quot;360&quot; /&gt;&lt;img src=&quot;https://github.com/VeritasYin/STGCN_IJCAI-18/raw/master/figures/STGCN.png&quot; width=&quot;450&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Paper: &lt;a href=&quot;https://doi.org/10.24963/ijcai.2018/505&quot;&gt;Spatio-Temporal Graph Convolutional Networks: A Deep Learning Framework for Traffic Forecasting.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Code: &lt;a href=&quot;https://github.com/VeritasYin/STGCN_IJCAI-18&quot;&gt;https://github.com/VeritasYin/STGCN_IJCAI-18&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;st-metanet-kdd-19-5&quot;&gt;ST-MetaNet (KDD-19) &lt;a class=&quot;citation&quot; href=&quot;#DBLP:conf/kdd/PanLW00Z19&quot;&gt;[5]&lt;/a&gt;&lt;/h2&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://github.com/panzheyi/ST-MetaNet/raw/master/overview.jpg&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Paper: &lt;a href=&quot;https://doi.org/10.1145/3292500.3330884&quot;&gt;Urban traffic prediction from spatio-temporal data using deep meta learning&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Code: &lt;a href=&quot;https://github.com/panzheyi/ST-MetaNet&quot;&gt;https://github.com/panzheyi/ST-MetaNet&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;graph-wavenet-ijcai-19-6&quot;&gt;Graph WaveNet (IJCAI-19) &lt;a class=&quot;citation&quot; href=&quot;#DBLP:conf/ijcai/WuPLJZ19&quot;&gt;[6]&lt;/a&gt;&lt;/h2&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://github.com/nnzhan/Graph-WaveNet/raw/master/fig/model.png&quot; width=&quot;400&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Paper: &lt;a href=&quot;https://doi.org/10.24963/ijcai.2019/264&quot;&gt;Graph WaveNet for Deep Spatial-Temporal Graph Modeling&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Code: &lt;a href=&quot;https://github.com/nnzhan/Graph-WaveNet&quot;&gt;https://github.com/nnzhan/Graph-WaveNet&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;gman-aaai-20-7&quot;&gt;GMAN (AAAI-20) &lt;a class=&quot;citation&quot; href=&quot;#DBLP:conf/aaai/ZhengFW020&quot;&gt;[7]&lt;/a&gt;&lt;/h2&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://github.com/zhengchuanpan/GMAN/raw/master/figure/GMAN.png&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Paper: &lt;a href=&quot;https://ojs.aaai.org/index.php/AAAI/article/view/5477&quot;&gt;GMAN: A Graph Multi-Attention Network for Traffic Prediction&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Code: &lt;a href=&quot;https://github.com/zhengchuanpan/GMAN&quot;&gt;https://github.com/zhengchuanpan/GMAN&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;stag-gcn-cikm-20-8&quot;&gt;STAG-GCN (CIKM-20) &lt;a class=&quot;citation&quot; href=&quot;#DBLP:conf/cikm/LuGJFZ20&quot;&gt;[8]&lt;/a&gt;&lt;/h2&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://github.com/RobinLu1209/STAG-GCN/raw/master/figures/system_model.png&quot; width=&quot;700&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Paper: &lt;a href=&quot;https://dl.acm.org/doi/10.1145/3340531.3411894&quot;&gt;Spatiotemporal Adaptive Gated Graph Convolution Network for Urban Traffic Flow Forecasting&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Code: &lt;a href=&quot;https://github.com/RobinLu1209/STAG-GCN&quot;&gt;https://github.com/RobinLu1209/STAG-GCN&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;agcrn-neurips-20-9&quot;&gt;AGCRN (NeurIPS-20) &lt;a class=&quot;citation&quot; href=&quot;#DBLP:conf/nips/0001YL0020&quot;&gt;[9]&lt;/a&gt;&lt;/h2&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/posts/AGCRN.png&quot; width=&quot;500&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Paper: &lt;a href=&quot;https://proceedings.neurips.cc/paper/2020/hash/ce1aad92b939420fc17005e5461e6f48-Abstract.html&quot;&gt;Adaptive Graph Convolutional Recurrent Network for Traffic Forecasting.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Code: &lt;a href=&quot;https://github.com/LeiBAI/AGCRN&quot;&gt;https://github.com/LeiBAI/AGCRN&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;traffic-transformer-tgis-20-10&quot;&gt;Traffic Transformer (TGIS-20) &lt;a class=&quot;citation&quot; href=&quot;#DBLP:journals/tgis/CaiJMYZ20&quot;&gt;[10]&lt;/a&gt;&lt;/h2&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/posts/TrafficTransformer.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Paper: &lt;a href=&quot;https://doi.org/10.1111/tgis.12644&quot;&gt;Traffic Transformer: Capturing the Continuity and Periodicity of Time Series for Traffic Forecasting.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;gts-iclr-21-11&quot;&gt;GTS (ICLR-21) &lt;a class=&quot;citation&quot; href=&quot;#DBLP:conf/iclr/Shang0B21&quot;&gt;[11]&lt;/a&gt;&lt;/h2&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/../../assets/img/posts/GTS-architecture.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Paper: &lt;a href=&quot;https://openreview.net/forum?id=WEHSlH5mOk&quot;&gt;Discrete Graph Structure Learning for Forecasting Multiple Time Series&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Code: &lt;a href=&quot;https://github.com/chaoshangcs/GTS&quot;&gt;https://github.com/chaoshangcs/GTS&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;references&quot;&gt;References&lt;/h1&gt;
&lt;ol class=&quot;bibliography&quot;&gt;&lt;li&gt;&lt;span id=&quot;manibardo2021deep&quot;&gt;[1]Manibardo, E.L. et al. 2021. Deep learning for road traffic forecasting: Does it make a difference? &lt;i&gt;IEEE Transactions on Intelligent Transportation Systems&lt;/i&gt;. (2021).&lt;/span&gt;

&lt;a href=&quot;https://ieeexplore.ieee.org/abstract/document/9447807&quot; target=&quot;_blank&quot;&gt;link&lt;/a&gt;


&lt;!-- &lt;pre&gt;@article{manibardo2021deep,
  title = {Deep learning for road traffic forecasting: Does it make a difference?},
  author = {Manibardo, Eric L and La{\~n}a, Ibai and Del Ser, Javier},
  journal = {IEEE Transactions on Intelligent Transportation Systems},
  year = {2021},
  publisher = {IEEE},
  url = {https://ieeexplore.ieee.org/abstract/document/9447807}
}
&lt;/pre&gt; --&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;jiang2021graph&quot;&gt;[2]Jiang, W. and Luo, J. 2021. Graph neural network for traffic forecasting: A survey. &lt;i&gt;arXiv preprint arXiv:2101.11174&lt;/i&gt;. (2021).&lt;/span&gt;

&lt;a href=&quot;https://arxiv.org/abs/2101.11174&quot; target=&quot;_blank&quot;&gt;link&lt;/a&gt;


&lt;!-- &lt;pre&gt;@article{jiang2021graph,
  title = {Graph neural network for traffic forecasting: A survey},
  author = {Jiang, Weiwei and Luo, Jiayun},
  journal = {arXiv preprint arXiv:2101.11174},
  year = {2021},
  url = {https://arxiv.org/abs/2101.11174}
}
&lt;/pre&gt; --&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;DBLP:conf/iclr/LiYS018&quot;&gt;[3]Li, Y. et al. 2018. Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic
               Forecasting. &lt;i&gt;6th International Conference on Learning Representations, ICLR 2018,
               Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track Proceedings&lt;/i&gt; (2018).&lt;/span&gt;

&lt;a href=&quot;https://openreview.net/forum?id=SJiHXGWAZ&quot; target=&quot;_blank&quot;&gt;link&lt;/a&gt;


&lt;!-- &lt;pre&gt;@inproceedings{DBLP:conf/iclr/LiYS018,
  author = {Li, Yaguang and Yu, Rose and Shahabi, Cyrus and Liu, Yan},
  title = {Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic
                 Forecasting},
  booktitle = {6th International Conference on Learning Representations, {ICLR} 2018,
                 Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track Proceedings},
  publisher = {OpenReview.net},
  year = {2018},
  url = {https://openreview.net/forum?id=SJiHXGWAZ},
  timestamp = {Thu, 25 Jul 2019 14:25:46 +0200},
  biburl = {https://dblp.org/rec/conf/iclr/LiYS018.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
&lt;/pre&gt; --&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;DBLP:conf/ijcai/YuYZ18&quot;&gt;[4]Yu, B. et al. 2018. Spatio-Temporal Graph Convolutional Networks: A Deep Learning Framework
               for Traffic Forecasting. &lt;i&gt;Proceedings of the Twenty-Seventh International Joint Conference on
               Artificial Intelligence, IJCAI 2018, July 13-19, 2018, Stockholm,
               Sweden&lt;/i&gt; (2018), 3634–3640.&lt;/span&gt;

&lt;a href=&quot;https://doi.org/10.24963/ijcai.2018/505&quot; target=&quot;_blank&quot;&gt;link&lt;/a&gt;


&lt;!-- &lt;pre&gt;@inproceedings{DBLP:conf/ijcai/YuYZ18,
  author = {Yu, Bing and Yin, Haoteng and Zhu, Zhanxing},
  editor = {Lang, J{\'{e}}r{\^{o}}me},
  title = {Spatio-Temporal Graph Convolutional Networks: {A} Deep Learning Framework
                 for Traffic Forecasting},
  booktitle = {Proceedings of the Twenty-Seventh International Joint Conference on
                 Artificial Intelligence, {IJCAI} 2018, July 13-19, 2018, Stockholm,
                 Sweden},
  pages = {3634--3640},
  publisher = {ijcai.org},
  year = {2018},
  url = {https://doi.org/10.24963/ijcai.2018/505},
  doi = {10.24963/ijcai.2018/505},
  timestamp = {Tue, 20 Aug 2019 16:19:08 +0200},
  biburl = {https://dblp.org/rec/conf/ijcai/YuYZ18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
&lt;/pre&gt; --&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;DBLP:conf/kdd/PanLW00Z19&quot;&gt;[5]Pan, Z. et al. 2019. Urban Traffic Prediction from Spatio-Temporal Data Using Deep Meta
               Learning. &lt;i&gt;Proceedings of the 25th ACM SIGKDD International Conference on
               Knowledge Discovery &amp;amp; Data Mining, KDD 2019, Anchorage, AK,
               USA, August 4-8, 2019&lt;/i&gt; (2019), 1720–1730.&lt;/span&gt;

&lt;a href=&quot;https://doi.org/10.1145/3292500.3330884&quot; target=&quot;_blank&quot;&gt;link&lt;/a&gt;


&lt;!-- &lt;pre&gt;@inproceedings{DBLP:conf/kdd/PanLW00Z19,
  author = {Pan, Zheyi and Liang, Yuxuan and Wang, Weifeng and Yu, Yong and Zheng, Yu and Zhang, Junbo},
  editor = {Teredesai, Ankur and Kumar, Vipin and Li, Ying and Rosales, R{\'{o}}mer and Terzi, Evimaria and Karypis, George},
  title = {Urban Traffic Prediction from Spatio-Temporal Data Using Deep Meta
                 Learning},
  booktitle = {Proceedings of the 25th {ACM} {SIGKDD} International Conference on
                 Knowledge Discovery {\&amp;} Data Mining, {KDD} 2019, Anchorage, AK,
                 USA, August 4-8, 2019},
  pages = {1720--1730},
  publisher = {{ACM}},
  year = {2019},
  url = {https://doi.org/10.1145/3292500.3330884},
  doi = {10.1145/3292500.3330884},
  timestamp = {Thu, 14 Oct 2021 09:50:02 +0200},
  biburl = {https://dblp.org/rec/conf/kdd/PanLW00Z19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
&lt;/pre&gt; --&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;DBLP:conf/ijcai/WuPLJZ19&quot;&gt;[6]Wu, Z. et al. 2019. Graph WaveNet for Deep Spatial-Temporal Graph Modeling. &lt;i&gt;Proceedings of the Twenty-Eighth International Joint Conference on
               Artificial Intelligence, IJCAI 2019, Macao, China, August 10-16,
               2019&lt;/i&gt; (2019), 1907–1913.&lt;/span&gt;

&lt;a href=&quot;https://doi.org/10.24963/ijcai.2019/264&quot; target=&quot;_blank&quot;&gt;link&lt;/a&gt;


&lt;!-- &lt;pre&gt;@inproceedings{DBLP:conf/ijcai/WuPLJZ19,
  author = {Wu, Zonghan and Pan, Shirui and Long, Guodong and Jiang, Jing and Zhang, Chengqi},
  editor = {Kraus, Sarit},
  title = {Graph WaveNet for Deep Spatial-Temporal Graph Modeling},
  booktitle = {Proceedings of the Twenty-Eighth International Joint Conference on
                 Artificial Intelligence, {IJCAI} 2019, Macao, China, August 10-16,
                 2019},
  pages = {1907--1913},
  publisher = {ijcai.org},
  year = {2019},
  url = {https://doi.org/10.24963/ijcai.2019/264},
  doi = {10.24963/ijcai.2019/264},
  timestamp = {Tue, 29 Dec 2020 18:40:48 +0100},
  biburl = {https://dblp.org/rec/conf/ijcai/WuPLJZ19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
&lt;/pre&gt; --&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;DBLP:conf/aaai/ZhengFW020&quot;&gt;[7]Zheng, C. et al. 2020. GMAN: A Graph Multi-Attention Network for Traffic Prediction. &lt;i&gt;The Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI
               2020, The Thirty-Second Innovative Applications of Artificial Intelligence
               Conference, IAAI 2020, The Tenth AAAI Symposium on Educational
               Advances in Artificial Intelligence, EAAI 2020, New York, NY, USA,
               February 7-12, 2020&lt;/i&gt; (2020), 1234–1241.&lt;/span&gt;

&lt;a href=&quot;https://aaai.org/ojs/index.php/AAAI/article/view/5477&quot; target=&quot;_blank&quot;&gt;link&lt;/a&gt;


&lt;!-- &lt;pre&gt;@inproceedings{DBLP:conf/aaai/ZhengFW020,
  author = {Zheng, Chuanpan and Fan, Xiaoliang and Wang, Cheng and Qi, Jianzhong},
  title = {{GMAN:} {A} Graph Multi-Attention Network for Traffic Prediction},
  booktitle = {The Thirty-Fourth {AAAI} Conference on Artificial Intelligence, {AAAI}
                 2020, The Thirty-Second Innovative Applications of Artificial Intelligence
                 Conference, {IAAI} 2020, The Tenth {AAAI} Symposium on Educational
                 Advances in Artificial Intelligence, {EAAI} 2020, New York, NY, USA,
                 February 7-12, 2020},
  pages = {1234--1241},
  publisher = {{AAAI} Press},
  year = {2020},
  url = {https://aaai.org/ojs/index.php/AAAI/article/view/5477},
  timestamp = {Tue, 02 Feb 2021 07:59:41 +0100},
  biburl = {https://dblp.org/rec/conf/aaai/ZhengFW020.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
&lt;/pre&gt; --&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;DBLP:conf/cikm/LuGJFZ20&quot;&gt;[8]Lu, B. et al. 2020. Spatiotemporal Adaptive Gated Graph Convolution Network for Urban
               Traffic Flow Forecasting. &lt;i&gt;CIKM ’20: The 29th ACM International Conference on Information
               and Knowledge Management, Virtual Event, Ireland, October 19-23, 2020&lt;/i&gt; (2020), 1025–1034.&lt;/span&gt;

&lt;a href=&quot;https://doi.org/10.1145/3340531.3411894&quot; target=&quot;_blank&quot;&gt;link&lt;/a&gt;


&lt;!-- &lt;pre&gt;@inproceedings{DBLP:conf/cikm/LuGJFZ20,
  author = {Lu, Bin and Gan, Xiaoying and Jin, Haiming and Fu, Luoyi and Zhang, Haisong},
  editor = {d'Aquin, Mathieu and Dietze, Stefan and Hauff, Claudia and Curry, Edward and Cudr{\'{e}}{-}Mauroux, Philippe},
  title = {Spatiotemporal Adaptive Gated Graph Convolution Network for Urban
                 Traffic Flow Forecasting},
  booktitle = {{CIKM} '20: The 29th {ACM} International Conference on Information
                 and Knowledge Management, Virtual Event, Ireland, October 19-23, 2020},
  pages = {1025--1034},
  publisher = {{ACM}},
  year = {2020},
  url = {https://doi.org/10.1145/3340531.3411894},
  doi = {10.1145/3340531.3411894},
  timestamp = {Thu, 14 Oct 2021 10:46:30 +0200},
  biburl = {https://dblp.org/rec/conf/cikm/LuGJFZ20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
&lt;/pre&gt; --&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;DBLP:conf/nips/0001YL0020&quot;&gt;[9]Bai, L. et al. 2020. Adaptive Graph Convolutional Recurrent Network for Traffic Forecasting. &lt;i&gt;Advances in Neural Information Processing Systems 33: Annual Conference
               on Neural Information Processing Systems 2020, NeurIPS 2020, December
               6-12, 2020, virtual&lt;/i&gt; (2020).&lt;/span&gt;

&lt;a href=&quot;https://proceedings.neurips.cc/paper/2020/hash/ce1aad92b939420fc17005e5461e6f48-Abstract.html&quot; target=&quot;_blank&quot;&gt;link&lt;/a&gt;


&lt;!-- &lt;pre&gt;@inproceedings{DBLP:conf/nips/0001YL0020,
  author = {Bai, Lei and Yao, Lina and Li, Can and Wang, Xianzhi and Wang, Can},
  editor = {Larochelle, Hugo and Ranzato, Marc'Aurelio and Hadsell, Raia and Balcan, Maria{-}Florina and Lin, Hsuan{-}Tien},
  title = {Adaptive Graph Convolutional Recurrent Network for Traffic Forecasting},
  booktitle = {Advances in Neural Information Processing Systems 33: Annual Conference
                 on Neural Information Processing Systems 2020, NeurIPS 2020, December
                 6-12, 2020, virtual},
  year = {2020},
  url = {https://proceedings.neurips.cc/paper/2020/hash/ce1aad92b939420fc17005e5461e6f48-Abstract.html},
  timestamp = {Tue, 19 Jan 2021 15:57:14 +0100},
  biburl = {https://dblp.org/rec/conf/nips/0001YL0020.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
&lt;/pre&gt; --&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;DBLP:journals/tgis/CaiJMYZ20&quot;&gt;[10]Cai, L. et al. 2020. Traffic transformer: Capturing the continuity and periodicity of time
               series for traffic forecasting. &lt;i&gt;Trans. GIS&lt;/i&gt;. 24, 3 (2020), 736–755. DOI:https://doi.org/10.1111/tgis.12644.&lt;/span&gt;

&lt;a href=&quot;https://doi.org/10.1111/tgis.12644&quot; target=&quot;_blank&quot;&gt;link&lt;/a&gt;


&lt;!-- &lt;pre&gt;@article{DBLP:journals/tgis/CaiJMYZ20,
  author = {Cai, Ling and Janowicz, Krzysztof and Mai, Gengchen and Yan, Bo and Zhu, Rui},
  title = {Traffic transformer: Capturing the continuity and periodicity of time
                 series for traffic forecasting},
  journal = {Trans. {GIS}},
  volume = {24},
  number = {3},
  pages = {736--755},
  year = {2020},
  url = {https://doi.org/10.1111/tgis.12644},
  doi = {10.1111/tgis.12644},
  timestamp = {Wed, 25 Nov 2020 10:55:45 +0100},
  biburl = {https://dblp.org/rec/journals/tgis/CaiJMYZ20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
&lt;/pre&gt; --&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;DBLP:conf/iclr/Shang0B21&quot;&gt;[11]Shang, C. et al. 2021. Discrete Graph Structure Learning for Forecasting Multiple Time Series. &lt;i&gt;9th International Conference on Learning Representations, ICLR 2021,
               Virtual Event, Austria, May 3-7, 2021&lt;/i&gt; (2021).&lt;/span&gt;

&lt;a href=&quot;https://openreview.net/forum?id=WEHSlH5mOk&quot; target=&quot;_blank&quot;&gt;link&lt;/a&gt;


&lt;!-- &lt;pre&gt;@inproceedings{DBLP:conf/iclr/Shang0B21,
  author = {Shang, Chao and Chen, Jie and Bi, Jinbo},
  title = {Discrete Graph Structure Learning for Forecasting Multiple Time Series},
  booktitle = {9th International Conference on Learning Representations, {ICLR} 2021,
                 Virtual Event, Austria, May 3-7, 2021},
  publisher = {OpenReview.net},
  year = {2021},
  url = {https://openreview.net/forum?id=WEHSlH5mOk},
  timestamp = {Wed, 23 Jun 2021 17:36:39 +0200},
  biburl = {https://dblp.org/rec/conf/iclr/Shang0B21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
&lt;/pre&gt; --&gt;&lt;/li&gt;&lt;/ol&gt;</content><author><name></name></author><category term="[&quot;AI&quot;]" /><summary type="html">Overview</summary></entry><entry><title type="html">Traffic Prediction</title><link href="/ai/2021/11/30/traffic-prediction.html" rel="alternate" type="text/html" title="Traffic Prediction" /><published>2021-11-30T15:43:00+09:00</published><updated>2021-11-30T15:43:00+09:00</updated><id>/ai/2021/11/30/traffic-prediction</id><content type="html" xml:base="/ai/2021/11/30/traffic-prediction.html">&lt;p&gt;Traffic prediction is one of the most interesting topics in recent AI conferences. Traffic prediction is challenging yet intriguing due to its temporal and spatial complexities. Since traffic values such as traffic volume or speed are measured in real numbers, it is rather easier to define a problem as follows:&lt;/p&gt;

\[[X^{(1)}, ..., X^{(t-1)};\mathcal{G}] \xrightarrow{h(\cdot)} \hat{X}^{(t)}\]

&lt;p&gt;Where \(X^{(t)} \in \mathbb{R}^{N_x}\) is a vector of traffic values of \(N_x\) sensors at timestamp \(t\), \(\mathcal{G}\) is a connection network between the traffic sensors, and \(h(\cdot)\) is a prediction model that can be assumed as a function. We normally evaluate the performance of the preiction model \(h(\cdot)\) using &lt;em&gt;mean absolute error (MAE)&lt;/em&gt;, &lt;em&gt;mean squared error (MSE)&lt;/em&gt;, &lt;em&gt;root mean squared error (RMSE)&lt;/em&gt;, &lt;em&gt;mean absolute percent error (MAPE)&lt;/em&gt;,  or &lt;em&gt;normalized mean absolute error (NMAE)&lt;/em&gt;. These evaluation metrics may also be used as loss function if the model is based on deep neural network.&lt;/p&gt;

&lt;p&gt;Although we first described the problem as we can use all the historical values to predict the next step, it is not feasible to require all the historical data for each next step prediction. Therefore, we may define a problem in rather narrowed down fashion as follows:&lt;/p&gt;

\[[X^{(t-P+1)}, ..., X^{(t)};\mathcal{G}] \xrightarrow{h(\cdot)} [\hat{X}^{(t+1)}, ..., \hat{X}^{(t+Q)}]\]

&lt;p&gt;Here we defined problem to predict next \(Q\) time stemps based on previous \(P\) time steps. This assumes that the temporal correlation pattern can be found within \(P\)- timesteps to predict the next \(Q\)- timesteps while the spatial correlation between the traffic sensors catched by the sensor network \(\mathcal{G}\).&lt;/p&gt;

&lt;p&gt;Here are some list of papers that you can consider as baselines.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;DCRNN&lt;/strong&gt; - Li, Yaguang, et al. “Diffusion convolutional recurrent neural network: Data-driven traffic forecasting.” arXiv preprint arXiv:1707.01926 (2017).&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;ST-MetaNet&lt;/strong&gt; - Pan, Zheyi, et al. “Urban traffic prediction from spatio-temporal data using deep meta learning.” Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp;amp; Data Mining. 2019.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;GMAN&lt;/strong&gt; - Zheng, Chuanpan, et al. “Gman: A graph multi-attention network for traffic prediction.” Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 34. No. 01. 2020.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Here are some of my favorite researchers who are working in this field.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://zhangjunbo.org/&quot;&gt;Junbo Zhang&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;script src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;</content><author><name></name></author><category term="[&quot;AI&quot;]" /><summary type="html">Traffic prediction is one of the most interesting topics in recent AI conferences. Traffic prediction is challenging yet intriguing due to its temporal and spatial complexities. Since traffic values such as traffic volume or speed are measured in real numbers, it is rather easier to define a problem as follows:</summary></entry></feed>